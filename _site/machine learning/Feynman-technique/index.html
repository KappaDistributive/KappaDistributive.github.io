<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.3 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>An Hommage to Feynman’s Technique - Stefan Mesken</title>
<meta name="description" content="Fragile Knowledge">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Stefan Mesken">
<meta property="og:title" content="An Hommage to Feynman’s Technique">
<meta property="og:url" content="/machine%20learning/Feynman-technique/">


  <meta property="og:description" content="Fragile Knowledge">





  <meta name="twitter:site" content="@mesken_stefan">
  <meta name="twitter:title" content="An Hommage to Feynman’s Technique">
  <meta name="twitter:description" content="Fragile Knowledge">
  <meta name="twitter:url" content="/machine%20learning/Feynman-technique/">

  
    <meta name="twitter:card" content="summary">
    
  

  



  <meta property="article:published_time" content="2019-06-17T00:00:00+02:00">





  

  


<link rel="canonical" href="/machine%20learning/Feynman-technique/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Stefan Mesken",
      "url": null,
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Stefan Mesken Feed">

<!-- Twitter cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@mesken_stefan">
<meta name="twitter:title" content="An Hommage to Feynman's Technique">


  <meta name="twitter:description"
    content="Fragile Knowledge


  I don’t know what’s the matter with people: they don’t learn by
understanding; they learn by some other way - by rote, or
something. Their knowledge is so fragile!

  – Richar...">



  <meta name="twitter:image"
    content="https://www.stefanmesken.info/images/avatar_twitter.png">

<!-- end of Twitter cards -->

<!-- ****** faviconit.com favicons ****** -->
	<link rel="shortcut icon" href="/assets/favicon/favicon.ico">
	<link rel="icon" sizes="16x16 32x32 64x64" href="/assets/favicon/favicon.ico">
	<link rel="icon" type="image/png" sizes="196x196" href="/assets/favicon/favicon-192.png">
	<link rel="icon" type="image/png" sizes="160x160" href="/assets/favicon/favicon-160.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/assets/favicon/favicon-96.png">
	<link rel="icon" type="image/png" sizes="64x64" href="/assets/favicon/favicon-64.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16.png">
	<link rel="apple-touch-icon" href="/assets/favicon/favicon-57.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/assets/favicon/favicon-114.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/favicon/favicon-72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/favicon/favicon-144.png">
	<link rel="apple-touch-icon" sizes="60x60" href="/assets/favicon/favicon-60.png">
	<link rel="apple-touch-icon" sizes="120x120" href="/assets/favicon/favicon-120.png">
	<link rel="apple-touch-icon" sizes="76x76" href="/assets/favicon/favicon-76.png">
	<link rel="apple-touch-icon" sizes="152x152" href="/assets/favicon/favicon-152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/favicon-180.png">
	<meta name="msapplication-TileColor" content="#FFFFFF">
	<meta name="msapplication-TileImage" content="/assets/favicon/favicon-144.png">
	<meta name="msapplication-config" content="/assets/favicon/browserconfig.xml">
	<!-- ****** faviconit.com favicons ****** -->

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">Stefan Mesken</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/blog/" >Blog</a>
            </li><li class="masthead__menu-item">
              <a href="/about.html" >About</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/images/avatar.png" alt="Stefan Mesken" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Stefan Mesken</h3>
    
    
      <p class="author__bio" itemprop="description">
        Mathematician and Data Scientist.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Cologne, Germany</span>
        </li>
      

      
        
          
        
          
        
          
            <li><a href="https://twitter.com/mesken_stefan" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
          
        
          
        
          
            <li><a href="https://github.com/KappaDistributive" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="An Hommage to Feynman’s Technique">
    <meta itemprop="description" content="Fragile Knowledge">
    <meta itemprop="datePublished" content="June 17, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">An Hommage to Feynman’s Technique
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  6 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <h1 id="fragile-knowledge">Fragile Knowledge</h1>

<blockquote>
  <p>I don’t know what’s the matter with people: they don’t learn by
understanding; they learn by some other way - by rote, or
something. Their knowledge is so fragile!</p>

  <p>– Richard P. Feynman</p>
</blockquote>

<p>One key to successfully mastering a new subject, I believe, is to
connect it to something that you are already deeply familiar
with. This idea is as old as human learning and a common quality of
great lecturers is that they fully embrace its logical conclusion:
When introducing an audience to any novel concept, start out by
conveying the main ideas in analogies and metaphors rather than
drowning them in complexities and details.</p>

<p>And while people tend to agree that this is a good quality in a
teacher, they often deprive themselves of this luxury when learning on
their own. Admittedly, explaining a new idea well to yourself requires
a substantial amount of additional effort. However, I am convinced
that this overhead is not only economical but of fundamental
importance if you ever plan to master a new set  of skills (as opposed to
gaining the mostly worthless knowledge of sparsely connected facts).</p>

<h1 id="case-study-understanding-neural-networks">Case Study: Understanding Neural Networks</h1>

<p>So, if you are still with me, I’d like to demonstrate how this might
look like when first learning about neural networks. Basically I’ll
try to reconstruct the inner monologue that went through my head when
I just first learned about them.</p>

<p>“Neural networks are basically <a href="https://en.wikipedia.org/wiki/Directed_graph">directed
graphs</a> with
metadata. Nodes represent neurons, edges represent the data-flow
between those neurons and the metadata comes in two flavours:</p>

<ol>
  <li>
    <p>The weight attached to every edge determines how much of an
influence its source neuron has in the overall network and</p>
  </li>
  <li>
    <p>An activation function, attached to each neuron, that determines the
‘shape’ of this neuron’s discharge pattern. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup></p>
  </li>
</ol>

<p>So far, so good. But what does that mean? How can a neural network
process information?”</p>

<p>Stepping out of character for a second: It’s here that you can make
life very difficult for yourself. Both leaving this question
unanswered and jumping into some complex example
(e.g. <a href="https://arxiv.org/abs/1512.03385">ResNet</a>) are, in my opinion,
terrible mistakes. You want to build a simple example, ideally relying
only on yourself, for two reasons:</p>

<ol>
  <li>First and most importantly: This is a litmus test. If you are not
able to build a basic example of the concept you’ve just learned
about, you haven’t understood the basics yet and need to revisit
them. By forcing yourself to sit down and actually spelling out a very
simple example in detail, you’re making sure that your previous gained
confidence is justified and that you’re not just fooling yourself.
    <blockquote>
      <p>The first principle is that you must not fool yourself – and you are
the easiest person to fool.</p>

      <p>– Richard P. Feynman</p>
    </blockquote>
  </li>
  <li>
    <p>If you want to master any subject, it is my firm opinion that you
must carry around a large set of examples in your head. These
examples will not only guide your intuition but they will also
serve as a more and more elaborate testing ground for new ideas. In
the future, if someone tells you about some new fancy concept (that
someone might be you), you can refer to an appropriate example in
your head and see how it would influence that. If the results don’t
make sense, something’s wrong! Either you’ve misunderstood what the
other party is telling you or there is a mistake. Assuming you want this
conversation to remain meaningful, you need to fix that! This is
how I, and how I believe most of my colleagues, are able to build
an appropriate intuition about complex concepts that often run
counter to any experience you might have had in your daily life.</p>

    <p>Building a simple example from scratch is your first step
toward assembling your internal database.</p>
  </li>
</ol>

<p>Okay, let’s return to the inner monologue:</p>

<p>“Is there anything I already know about that could easily be realized
as a neural network? Actually, yes: Linear functions are of the form
\(f(x) = a \cdot x + b\) and they are represented by the following
neural network: <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup></p>

<figure style="align: center">
  <img src="/images/diagrams/nn_linear_function.png" style="max-width: 400px;" alt="a neural network that represents a linear function" />
</figure>

<p>Great, but how about logical connections? If artificial neural
networks are supposed to model actual neural networks, they certainly
must be able to capture logic gates, right? Right!</p>

<figure style="align: center">
  <img src="/images/diagrams/nn_not.png" style="max-width: 400px;" alt="a neural network that represents logical negation" />
</figure>

<p>Here \(\chi = \chi_{[0, \infty)}\) is the activation function of
\(a_1\) and all you need to know is that \(\chi(z) = 0\) for all \(z
&lt; 0\) and \(\chi(z) = 1\) for all \(z \ge 0\). So, if we set \(x_1 =
0\), we get that \(a_1 = \chi(w_0 \cdot x_0 + w_1 \cdot x_1) =
\chi(0 \cdot 1 + (-1) \cdot 0) = \chi(0) = 0\). On the other hand, if we let
\(x_1 = 1\), we get that \(a_1 = \chi(0 \cdot 1 + (-1) \cdot 1) = \chi(-1) =
0\). So this neural network does indeed represent \(\mathrm{NOT}(x_1)\)!”</p>

<p>At this point, you might want to cook up a few more examples and in an
earlier tweet I demonstrated how to represent other basic logic gates
(AND, OR, NOR, XOR, XNOR) as neural networks as well. I’d encourage
you to try it yourself first and then <a href="https://twitter.com/mesken_stefan/status/1138694458470539264">hop over to
Twitter</a>
and compare your results with mine. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote">3</a></sup></p>

<p>Once you’ve done that, you may notice what I’ve noticed: Not only can
neural networks represent logic gates. <em>Neural networks are nothing
more than logic gates</em>, with a few minor adjustments:</p>

<ol>
  <li>
    <p>Inputs are allowed to take on any real number as value, not just \(0\) and \(1\),</p>
  </li>
  <li>
    <p>We add a restriction that a node’s value is computed by a weighted,
linear combination of the values to its left followed by an
activation function and</p>
  </li>
  <li>
    <p>We add an activation functions to our nodes. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote">4</a></sup>”</p>
  </li>
</ol>

<p>It may not seem that way, but this little detour is incredibly
beneficial to your overall learning strategy. <strong>Ideas and memories die
in a vacuum</strong>. If you want them to become lasting and meaningful, you
need to them connect to as many previously established ideas as
possible. Don’t believe me? Then tell me: What did you have for dinner
last Wednesday? Unless you are able to connect last Wednesday’s dinner
to something more meaningful (maybe you happened to be on a first
date), most of us will struggle mightily with this very simple
question. And if I ask you about your lunch a year ago, there’s
basically no chance you’ll be able to remember. On the other hand, if
I ask you what you did last Christmas (or even better: On your wedding
day if you happen to be married), the task becomes much easier. You
either connect ideas and memories or you will lose them –
quickly. Not only that: Sparsely connected ideas (what Feynman calls
‘fragile knowledge’) are basically worthless as they’re not readily
available to be used in similar, but slightly different, settings.</p>

<h1 id="what-you-should-take-away-from-this">What you should take away from this</h1>

<p>If you make a habit of <em>always</em> explaining new ideas to yourself until
you’ve completely broken them down to related concepts, that you’ve
already mastered, you’ll never have to learn or memorize anything
truly novel again. And, over time, you’ll gain firm, deeply connected,
foundational knowledge about seemingly unrelated concepts that will
not only help you to learn other concepts faster and more efficient
but, ultimately, also allow you to solve problems in surprising,
efficient and truly ingenious ways. Being able to do that is, in a
nutshell, the mark of a true expert.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I think it’s helpful to point out that this is one of the ways
that artificial neural networks differ from biological
ones. Biological neurons either fire or they don’t – so, in a
way, the only activation function they’re allowed to have is the
<a href="https://en.wikipedia.org/wiki/Indicator_function">characteristic
function</a>
\(\chi_{(-\infty, a]}\) for some number \(a\). <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This follows Andrew Ng’s handy convention that any neuron/weight with
a \(0\) as subscript represents a bias component – independent of the input. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>In case you don’t want to use Twitter, you can find my solution <a href="http://localhost:4000/images/diagrams/nn_logic_gates.png">here</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>This point, in theory, is incredibly powerful. In fact, it’s too
powerful. Since neural networks are intended to approximate some
function \(f\) to begin with, we could always achieve this by
taking \(f\) as our activation function. In practice, however,
\(f\) is unknown, we only allow activation functions from a very
restrictive, simple set of functions and their specific choice, in
many cases, turns out to be surprisingly irrelevant. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#human-learning" class="page__taxonomy-item" rel="tag">human learning</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#machine-learning" class="page__taxonomy-item" rel="tag">machine learning</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#neural-networks" class="page__taxonomy-item" rel="tag">neural networks</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#machine-learning" class="page__taxonomy-item" rel="tag">Machine Learning</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2019-06-17T00:00:00+02:00">June 17, 2019</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?via=mesken_stefan&text=An+Hommage+to+Feynman%27s+Technique%20%2Fmachine%2520learning%2FFeynman-technique%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=%2Fmachine%2520learning%2FFeynman-technique%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=%2Fmachine%2520learning%2FFeynman-technique%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/machine%20learning/tensorflow-without-tears/" class="pagination--pager" title="TensorFlow Without Tears
">Previous</a>
    
    
      <a href="/data-science/metrics/" class="pagination--pager" title="The Dangers of Performance Metrics
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/data-science/machine-learning-golf/" rel="permalink">Machine Learning Golf
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  3 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">For the last 5 years or so, I’ve been lurking on the Code Golf Stackexchange. Code Golf is the art of solving a given problem, under specified rules, with as...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/data-science/metrics/" rel="permalink">The Dangers of Performance Metrics
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  6 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Full disclosure: I’m not a big fan of one-dimensional metrics when evaluating (binary) classifiers
(e.g. a neural network that is supposed to distinguish pic...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/machine%20learning/tensorflow-without-tears/" rel="permalink">TensorFlow Without Tears
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  5 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Life is pretty crazy right now. Finishing a PhD, changing from set theory to applied data science, forming connections to other data scientists, learning as ...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/machine%20learning/how-to-beat-kaggle-(the-easy-way)/" rel="permalink">How To Beat Kaggle (the Easy Way)
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  7 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">A few nights ago, I found myself tinkering with the Titanic data set on Kaggle and couldn’t help but notice the number of people with a perfect score – many ...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Stefan Mesken. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js" integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous"></script>










<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



  </body>
</html>
